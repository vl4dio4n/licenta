{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, average_precision_score\n",
    "from typing import List\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_hist(precision, recall, f1_score, auroc, auprc, fpr, fnr, fig_name):\n",
    "    metrics = [\"Precision\", \"Recall\", \"F1-score\", \"AUROC\", \"AUPRC\", \"FPR\", \"FNR\"]\n",
    "    values = [precision, recall, f1_score, auroc, auprc, fpr, fnr]\n",
    "\n",
    "    percentages = [v * 100 for v in values]\n",
    "    colors = [\"blue\", \"green\", \"red\", \"orange\", \"magenta\", \"yellow\", \"pink\"]\n",
    "\n",
    "    plt.figure(figsize=(5.5, 10))\n",
    "    bars = plt.bar(metrics, percentages, color=colors, width=1)\n",
    "    plt.ylim(0, 100)\n",
    "\n",
    "    for bar, value in zip(bars, percentages):\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, yval + 1, f'{value:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "    plt.title('Metrics')\n",
    "    plt.ylabel('Percentage')\n",
    "\n",
    "    plt.savefig(f\"../images/metrics/{fig_name}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, inliers_label, outliers_label):\n",
    "    y_true[y_true == inliers_label] = 0\n",
    "    y_true[y_true == outliers_label] = 1\n",
    "    y_pred[y_pred == inliers_label] = 0\n",
    "    y_pred[y_pred == outliers_label] = 1\n",
    "\n",
    "    print(f\"true_inliers: {np.sum(y_true == 0)}\")\n",
    "    print(f\"true_outliers: {np.sum(y_true == 1)}\")\n",
    "    print(f\"pred_inliers: {np.sum(y_pred == 0)}\")\n",
    "    print(f\"pred_outliers: {np.sum(y_pred == 1)}\")\n",
    "\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    auprc = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    fpr = fp / (fp + tn)\n",
    "    fnr = fn / (fn + tp)\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1}\")\n",
    "    print(f\"AUROC: {auroc}\")\n",
    "    print(f\"AUPRC: {auprc}\")\n",
    "    print(f\"False Positive Rate (FPR): {fpr}\")\n",
    "    print(f\"False Negative Rate (FNR): {fnr}\")\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(f\"tp: {tp}, fp: {fp}, tn: {tn}, fn: {fn}\")\n",
    "\n",
    "    return precision, recall, f1, auroc, auprc, fpr, fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(inliers_label, outliers_label, labels):\n",
    "    labels[labels == 1] = outliers_label\n",
    "    labels[labels == 0] = inliers_label\n",
    "    labels = labels.astype(np.int8)\n",
    "    num_inliers = np.sum(labels == inliers_label)\n",
    "    num_outliers = np.sum(labels == outliers_label)\n",
    "    print(f\"num_inliers: {num_inliers}, inliers_ratio: {num_inliers / (num_inliers + num_outliers)}\")\n",
    "    print(f\"num_outliers: {num_outliers}, outliers_ratio: {num_outliers / (num_inliers + num_outliers)}\")\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events_from_logs(file_path):\n",
    "    def get_log_template(template: str):\n",
    "        template = template.replace(\".\", \"\\.\")\n",
    "        template = template.replace(\"(\", \"\\(\")\n",
    "        template = template.replace(\")\", \"\\)\")\n",
    "        template = template.replace(\"[\", \"\\[\")\n",
    "        template = template.replace(\"]\", \"\\]\")\n",
    "        template = template.replace(\"$\", \"\\$\")\n",
    "        template = template.replace(\"<*>\", \"(.*)\")\n",
    "        template = \"(.*) \" + template\n",
    "        return template.strip()\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        return pd.read_csv(file_path)\n",
    "\n",
    "    event_templates_df = pd.read_csv('../datasets/BGL/BGL_templates.csv')\n",
    "    event_templates = event_templates_df[\"EventTemplate\"].apply(get_log_template)\n",
    "    template_res = [re.compile(template) for template in event_templates]\n",
    "    num_events = len(template_res) + 1\n",
    "\n",
    "    logs_file_path = \"../datasets/BGL/BGL.log\"\n",
    "    num_logs = 4747963\n",
    "    labels = []\n",
    "    events = []\n",
    "    log_ids = []\n",
    "    time_intervals = []\n",
    "\n",
    "    with open(logs_file_path, \"r\") as file:\n",
    "        cnt_matches = 0\n",
    "        cnt_logs = 0\n",
    "        last_time = 0\n",
    "        for log in tqdm(file, total=num_logs, desc=\"Preprocessing logs\"):\n",
    "            log = log.strip()\n",
    "            current_time = int(log.split(\" \")[1])\n",
    "            cnt_logs += 1\n",
    "            ok = 0\n",
    "            for index, template_re in enumerate(template_res):\n",
    "                match = template_re.fullmatch(log)\n",
    "                if match:\n",
    "                    cnt_matches += 1\n",
    "                    ok = 1\n",
    "                    events.append(index + 1)\n",
    "                    break\n",
    "            if last_time == 0:\n",
    "                last_time = current_time \n",
    "            if ok == 0:\n",
    "                events.append(num_events)    \n",
    "            log_ids.append(cnt_logs)\n",
    "            labels.append(0 if log[0] == \"-\" else 1)\n",
    "            time_intervals.append(current_time - last_time)\n",
    "            last_time = current_time\n",
    "\n",
    "        print(f\"{cnt_matches}/{cnt_logs} matches\")\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"LogId\": log_ids,\n",
    "        \"Event\": events,\n",
    "        \"Label\": labels,\n",
    "        \"TimeInterval\": time_intervals\n",
    "    })\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_traces(window_size=256, step_size=128):\n",
    "    file_name = f\"window_size={window_size}-step_size={step_size}.npz\"\n",
    "    file_path = f\"../datasets/BGL/event_traces/{file_name}\"\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        event_traces = np.load(file_path)\n",
    "        windows = event_traces[\"windows\"]\n",
    "        window_labels = event_traces[\"labels\"]\n",
    "        return windows, window_labels\n",
    "    \n",
    "    bgl_events_df = get_events_from_logs(\"../datasets/BGL/BGL_events.csv\")\n",
    "    events = bgl_events_df[\"Event\"].values\n",
    "    labels = bgl_events_df[\"Label\"].values\n",
    "    time_intervals = bgl_events_df[\"TimeInterval\"].values\n",
    "\n",
    "    num_events = events.shape[0]\n",
    "    window_labels = []\n",
    "    windows = []\n",
    "\n",
    "    for i in tqdm(range(0, num_events, step_size), desc=\"Creating event traces windows\"):\n",
    "        window = None\n",
    "        if i + window_size <= num_events: \n",
    "            window = np.concatenate([events[i:i + window_size], time_intervals[i:i + window_size]], axis=0)\n",
    "            label = np.sum(labels[i:i + window_size], axis=0)\n",
    "        else:\n",
    "            window = np.concatenate([events[i:], np.array([0] * (i + window_size - num_events)), time_intervals[i:], np.array([0] * (i + window_size - num_events))])\n",
    "            label = np.sum(labels[i:], axis=0)\n",
    "        window_labels.append(1 if label > 0 else 0)\n",
    "        windows.append(window)\n",
    "\n",
    "    windows = np.array(windows)\n",
    "    window_labels = np.array(window_labels).astype(np.int8)\n",
    "    np.savez(file_path, windows=windows, labels=window_labels)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    windows = scaler.fit_transform(windows)\n",
    "\n",
    "    return windows, window_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_occurrence(window_size=1000, step_size=50, num_events=378):\n",
    "    def get_event_occurence(window, num_events):\n",
    "        event_occurrence = np.zeros(num_events)\n",
    "        for i in range(1, num_events + 1):\n",
    "            event_occurrence[i - 1] = np.sum(window == i)\n",
    "        return event_occurrence\n",
    "\n",
    "\n",
    "    file_name = f\"window_size={window_size}-step_size={step_size}.npz\"\n",
    "    file_path = f\"../datasets/BGL/event_occurrence/{file_name}\"\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        event_traces = np.load(file_path)\n",
    "        windows = event_traces[\"windows\"]\n",
    "        window_labels = event_traces[\"labels\"]\n",
    "        return windows, window_labels\n",
    "    \n",
    "    bgl_events_df = get_events_from_logs(\"../datasets/BGL/BGL_events.csv\")\n",
    "    events = bgl_events_df[\"Event\"].values\n",
    "    labels = bgl_events_df[\"Label\"].values\n",
    "\n",
    "    num_logs = events.shape[0]\n",
    "    windows = []\n",
    "    window_labels = []\n",
    "\n",
    "    for i in tqdm(range(0, num_logs, step_size), desc=\"Creating event occurrence windows\"):\n",
    "        window = None\n",
    "        if i + window_size <= num_logs: \n",
    "            window = get_event_occurence(events[i:i + window_size], num_events)\n",
    "            label = np.sum(labels[i:i + window_size], axis=0)\n",
    "        else:\n",
    "            window = get_event_occurence(events[i:], num_events)\n",
    "            label = np.sum(labels[i:], axis=0)\n",
    "        windows.append(window)\n",
    "        window_labels.append(1 if label > 0 else 0)\n",
    "\n",
    "    windows = np.array(windows)\n",
    "    window_labels = np.array(window_labels).astype(np.int8)\n",
    "    np.savez(file_path, windows=windows, labels=window_labels)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    windows = scaler.fit_transform(windows)\n",
    "\n",
    "    return windows, window_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_ocsvm(classifier, data, labels, inliers_label, outliers_label, num_models=5, kernel=\"rbf\", train_size=0.2, contamination=0.3, gamma=\"scale\"):\n",
    "    models = []\n",
    "\n",
    "    for _ in tqdm(range(num_models), desc=\"Training One-Clss SVMs\"):\n",
    "        x_train, _, _, _ = train_test_split(data, labels, train_size=train_size, random_state=None)\n",
    "        ocsvm = classifier(kernel=kernel, nu=contamination, gamma=gamma)\n",
    "        ocsvm.fit(x_train)\n",
    "        models.append(ocsvm)    \n",
    "\n",
    "    predictions = np.zeros((data.shape[0], num_models))\n",
    "    for i, model in enumerate(tqdm(models, desc=\"Computing predictions\")):\n",
    "        preds = model.predict(data)\n",
    "        predictions[:, i] = (preds == outliers_label).astype(int)\n",
    "\n",
    "    pred_labels = (predictions.sum(axis=1) >= (num_models // 2)).astype(int)\n",
    "    pred_labels = np.where(pred_labels == 1, outliers_label, inliers_label)\n",
    "\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocsvm_experiment(classifier, inliers_label, outliers_label, title, num_events, kernel=\"rbf\", train_size=0.2, contamination=0.3, gamma=\"scale\", window_size=256, step_size=128, experiment_type=\"occurrence_matrix\"):\n",
    "    data = None\n",
    "    if experiment_type == \"event_occurrence\":\n",
    "        data, labels = get_event_occurrence(window_size, step_size, num_events)\n",
    "    elif experiment_type == \"event_traces\":\n",
    "        data, labels = get_event_traces(window_size, step_size)\n",
    "    else:\n",
    "        return\n",
    "    labels = label_data(inliers_label, outliers_label, labels)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, train_size=train_size, random_state=42)\n",
    "    ocsvm =  classifier(kernel=kernel, nu=contamination, gamma=gamma)\n",
    "\n",
    "    ocsvm.fit(x_train)\n",
    "    y_test_pred = ocsvm.predict(x_test)\n",
    "\n",
    "    precision, recall, f1, auroc, auprc, fpr, fnr = compute_metrics(y_test, y_test_pred, inliers_label, outliers_label)\n",
    "    metrics_hist(precision, recall, f1, auroc, auprc, fpr, fnr, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_ocsvm_experiment(classifier, inliers_label, outliers_label, title, num_events, num_models=5, kernel=\"rbf\", train_size=0.2, contamination=0.3, gamma=\"scale\", window_size=256, step_size=128, experiment_type=\"event_occurrence\"):\n",
    "    data = None\n",
    "    if experiment_type == \"event_occurrence\":\n",
    "        data, labels = get_event_occurrence(window_size, step_size, num_events)\n",
    "    elif experiment_type == \"event_traces\":\n",
    "        data, labels = get_event_traces(window_size, step_size)\n",
    "    else:\n",
    "        return\n",
    "    labels = label_data(inliers_label, outliers_label, labels)\n",
    "\n",
    "    pred_labels = ensemble_ocsvm(\n",
    "        classifier=classifier, \n",
    "        data=data,\n",
    "        labels=labels,\n",
    "        inliers_label=inliers_label,\n",
    "        outliers_label=outliers_label, \n",
    "        num_models=num_models, \n",
    "        kernel=kernel, \n",
    "        train_size=train_size, \n",
    "        contamination=contamination, \n",
    "        gamma=gamma)\n",
    "\n",
    "    precision, recall, f1, auroc, auprc, fpr, fnr = compute_metrics(labels, pred_labels, inliers_label, outliers_label)\n",
    "    metrics_hist(precision, recall, f1, auroc, auprc, fpr, fnr, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_svdd_experiment(inliers_label, outliers_label, title, num_events, train_size=0.2, window_size=256, step_size=128, experiment_type=\"occurrence_matrix\",\n",
    "                         c=None, use_ae=False, hidden_neurons=None, hidden_activation='relu', output_activation='sigmoid', optimizer='adam', epochs=100, \n",
    "                         batch_size=32, dropout_rate=0.2, l2_regularizer=0.1, validation_size=0.1, preprocessing=True, verbose=1, random_state=None, contamination=0.1):\n",
    "    data = None\n",
    "    if experiment_type == \"event_occurrence\":\n",
    "        data, labels = get_event_occurrence(window_size, step_size, num_events)\n",
    "    elif experiment_type == \"event_traces\":\n",
    "        data, labels = get_event_traces(window_size, step_size)\n",
    "    else:\n",
    "        return\n",
    "    labels = label_data(inliers_label, outliers_label, labels)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, train_size=train_size, random_state=42)\n",
    "    model = DeepSVDD(c=c, use_ae=use_ae, hidden_neurons=hidden_neurons, hidden_activation=hidden_activation, output_activation=output_activation,\n",
    "                     optimizer=optimizer, epochs=epochs, batch_size=batch_size, dropout_rate=dropout_rate, l2_regularizer=l2_regularizer, \n",
    "                     validation_size=validation_size, preprocessing=preprocessing, verbose=verbose, random_state=random_state, contamination=contamination)\n",
    "    \n",
    "    model.fit(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    precision, recall, f1, auroc, auprc, fpr, fnr = compute_metrics(y_test, y_test_pred, inliers_label, outliers_label)\n",
    "    metrics_hist(precision, recall, f1, auroc, auprc, fpr, fnr, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_ocsvm_experiment(classifier, inliers_label, outliers_label, title, num_events, kernel=\"rbf\", gamma=\"scale\", train_size=0.2, window_size=256, step_size=128, experiment_type=\"occurrence_matrix\",\n",
    "                         hidden_neurons=None, hidden_activation='relu', output_activation='sigmoid', optimizer='adam', epochs=100, \n",
    "                         batch_size=32, dropout_rate=0.2, l2_regularizer=0.1, validation_size=0.1, preprocessing=True, verbose=1, random_state=None, contamination=0.1):\n",
    "    data = None\n",
    "    if experiment_type == \"event_occurrence\":\n",
    "        data, labels = get_event_occurrence(window_size, step_size, num_events)\n",
    "    elif experiment_type == \"event_traces\":\n",
    "        data, labels = get_event_traces(window_size, step_size)\n",
    "    else:\n",
    "        return\n",
    "    labels = label_data(inliers_label, outliers_label, labels)\n",
    "    \n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, train_size=train_size, random_state=42)\n",
    "    autoencoder = AutoEncoder(hidden_neurons=hidden_neurons, hidden_activation=hidden_activation, output_activation=output_activation,\n",
    "                     optimizer=optimizer, epochs=epochs, batch_size=batch_size, dropout_rate=dropout_rate, l2_regularizer=l2_regularizer, \n",
    "                     validation_size=validation_size, preprocessing=preprocessing, verbose=verbose, random_state=random_state, \n",
    "                     contamination=contamination)\n",
    "    \n",
    "    autoencoder.fit(x_train)\n",
    "    \n",
    "    bottleneck_layer = len(hidden_neurons) // 2 if hidden_neurons else 1\n",
    "    encoder_model = Model(inputs=autoencoder.model_.input, outputs=autoencoder.model_.get_layer(index=bottleneck_layer).output)\n",
    "    \n",
    "    x_train_encoded = encoder_model.predict(x_train)\n",
    "    x_test_encoded = encoder_model.predict(x_test)\n",
    "\n",
    "    ocsvm = classifier(kernel=kernel, gamma=gamma, nu=contamination)\n",
    "    ocsvm.fit(x_train_encoded)\n",
    "\n",
    "    y_test_pred = ocsvm.predict(x_test_encoded)\n",
    "\n",
    "    precision, recall, f1, auroc, auprc, fpr, fnr = compute_metrics(y_test, y_test_pred, inliers_label, outliers_label)\n",
    "    metrics_hist(precision, recall, f1, auroc, auprc, fpr, fnr, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "################ Scikit OCSVM Experiment #################\n",
    "##########################################################\n",
    "\n",
    "train_size = 0.5\n",
    "num_events = 378\n",
    "kernel = \"rbf\"\n",
    "contamination = 0.3\n",
    "gamma = \"scale\"\n",
    "window_size = 512\n",
    "step_size = 32\n",
    "experiment_type=\"event_occurrence\"\n",
    "\n",
    "ocsvm_experiment(\n",
    "    classifier=OneClassSVM,\n",
    "    inliers_label=1,\n",
    "    outliers_label=-1,\n",
    "    title=f\"bgl-scikit-{experiment_type}-ocsvm-train_size={train_size}-kernel={kernel}-nu={contamination}-gamma={gamma}-window_size={window_size}-step_size={step_size}\",\n",
    "    num_events = num_events,\n",
    "    kernel=kernel,\n",
    "    train_size=train_size,\n",
    "    contamination=contamination,\n",
    "    gamma=gamma,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size,\n",
    "    experiment_type=experiment_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "################ Scikit Event Traces OCSVM Experiment #################\n",
    "#######################################################################\n",
    "\n",
    "train_size = 0.8\n",
    "num_events = 378\n",
    "kernel = \"rbf\"\n",
    "contamination = 0.3\n",
    "gamma = \"scale\"\n",
    "window_size = 256\n",
    "step_size = 128\n",
    "experiment_type = \"event_traces\"\n",
    "\n",
    "ocsvm_experiment(\n",
    "    classifier=OneClassSVM,\n",
    "    inliers_label=1,\n",
    "    outliers_label=-1,\n",
    "    title=f\"bgl-scikit-{experiment_type}-ocsvm-train_size={train_size}-kernel={kernel}-nu={contamination}-gamma={gamma}-window_size={window_size}-step_size={step_size}\",\n",
    "    num_events = num_events,\n",
    "    kernel=kernel,\n",
    "    train_size=train_size,\n",
    "    contamination=contamination,\n",
    "    gamma=gamma,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size,\n",
    "    experiment_type=experiment_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "################ Scikit Event Occurrence Ensemble OCSVM Experiment #################\n",
    "####################################################################################\n",
    "\n",
    "train_size = 0.3\n",
    "num_events = 378\n",
    "kernel = \"rbf\"\n",
    "contamination = 0.2\n",
    "num_models = 5\n",
    "gamma = \"scale\"\n",
    "window_size = 512\n",
    "step_size = 32\n",
    "experiment_type = \"event_occurrence\"\n",
    "\n",
    "ensemble_ocsvm_experiment(\n",
    "    classifier=OneClassSVM, \n",
    "    inliers_label=1, \n",
    "    outliers_label=-1, \n",
    "    title=f\"bgl-scikit-{experiment_type}-ensemble-ocsvm-train_size={train_size}-kernel={kernel}-nu={contamination}-gamma={gamma}-window_size={window_size}-step_size={step_size}\",\n",
    "    num_events=num_events, \n",
    "    num_models=num_models, \n",
    "    kernel=kernel, \n",
    "    train_size=train_size, \n",
    "    contamination=contamination, \n",
    "    gamma=gamma,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size,\n",
    "    experiment_type=experiment_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "################ Scikit Event Traces Ensemble OCSVM Experiment #################\n",
    "####################################################################################\n",
    "\n",
    "train_size = 0.3\n",
    "num_events = 378\n",
    "kernel = \"rbf\"\n",
    "contamination = 0.3\n",
    "num_models = 5\n",
    "gamma = \"scale\"\n",
    "window_size = 256\n",
    "step_size = 32\n",
    "experiment_type = \"event_traces\"\n",
    "\n",
    "ensemble_ocsvm_experiment(\n",
    "    classifier=OneClassSVM, \n",
    "    inliers_label=1, \n",
    "    outliers_label=-1, \n",
    "    title=f\"bgl-scikit-{experiment_type}-ensemble-ocsvm-train_size={train_size}-kernel={kernel}-nu={contamination}-gamma={gamma}-window_size={window_size}-step_size={step_size}\",\n",
    "    num_events=num_events, \n",
    "    num_models=num_models, \n",
    "    kernel=kernel, \n",
    "    train_size=train_size, \n",
    "    contamination=contamination, \n",
    "    gamma=gamma,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size,\n",
    "    experiment_type=experiment_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "################ PyOd Event Occurrence Deep-SVDD Experiment #################\n",
    "#############################################################################\n",
    "\n",
    "train_size = 0.8\n",
    "num_events = 378\n",
    "contamination = 0.3\n",
    "experiment_type = \"event_occurrence\"\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "window_size = 512\n",
    "step_size = 32\n",
    "\n",
    "deep_svdd_experiment(\n",
    "    inliers_label=0,\n",
    "    outliers_label=1,\n",
    "    title=f\"bgl-deep-svdd-{experiment_type}-train_size={train_size}-epochs={epochs}-contamination={contamination}-window_size={window_size}-step_size={step_size}\",\n",
    "    num_events=num_events,\n",
    "    train_size=train_size,\n",
    "    experiment_type=experiment_type,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=2,\n",
    "    contamination=contamination,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "################ PyOd Event Occurrence AE-OCSVM Experiment #################\n",
    "############################################################################\n",
    "\n",
    "train_size = 0.8\n",
    "num_events = 378\n",
    "contamination = 0.3\n",
    "experiment_type = \"event_occurrence\"\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "window_size = 512\n",
    "step_size = 32\n",
    "gamma = \"auto\"\n",
    "kernel = \"rbf\"\n",
    "hidden_neurons = [64, 32, 32, 64]\n",
    "\n",
    "\n",
    "ae_ocsvm_experiment(\n",
    "    classifier=OneClassSVM,\n",
    "    inliers_label=1,\n",
    "    outliers_label=-1, \n",
    "    title=f\"hdfs-ae-ocsvm-{experiment_type}-train_size={train_size}-epochs={epochs}-contamination={contamination}-window_size={window_size}-step_size={step_size}\",\n",
    "    num_events=num_events, \n",
    "    kernel=kernel,\n",
    "    gamma=gamma,\n",
    "    train_size=train_size,  \n",
    "    experiment_type=experiment_type,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size, \n",
    "    verbose=2, \n",
    "    contamination=contamination,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
